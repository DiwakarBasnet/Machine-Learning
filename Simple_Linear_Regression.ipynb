{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Ypy7ByTotMaLtjQlqSKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiwakarBasnet/Machine-Learning/blob/main/Simple_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Lienar Regression"
      ],
      "metadata": {
        "id": "ThHbNKqmltOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple linear regression model to study relationship between sales and advertising dataset for dietary weight control product. In this project ther is one independent or input variable; Sales data and is denoted by X. Similarly, there is on dependent or output variable; Advertising data denoted by y. The linear relationship can be modelled by mathematical equation of the form:-\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathbf{y} = B_0 + B_1*X\n",
        "\\end{align}\n",
        "\n",
        "Slope of line is given by $B_1$ and intercept by $B_0$. In SLR model, we want to fit a line which estimates the linear relationship between $X$ and $y$. We can draw a scatter plot between $X$ and $y$ which shows the relationship between them.\n",
        "\n",
        "Now, our task is to find a line which best fits the scatter plot. This line is called **Regression line**.\n",
        "\n",
        "We can define an error function for any line. The regression line is made such that error function is minimized, this error function is also called **Cost function**."
      ],
      "metadata": {
        "id": "jW6pZDsYl39a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Function"
      ],
      "metadata": {
        "id": "WGv7YI98OFzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want the regression line to be close to actual data points as much as possible. It can be achieved by minimizing the vertical distance **(residual)** between the actual data point and fitted line.\n",
        "\n",
        "So, in a regression model, we try to minimize the residuals. We could try to do this by minimizing the sum of residuals, but then a large positive residual would cancel out a large negative residual. For this reason, we minimize the sum of the squares of the residuals.\n",
        "\n",
        "Let yi be actual data point and yi' is predicted data point. So, the residual for data point would be given as;\n",
        "\n",
        "\\begin{align}\n",
        "    \\mathbf{d_i} = y_i - y_i'\n",
        "\\end{align}\n",
        "\n",
        "Sum of the squares of the residuals is given as:\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathbf{D} = \\sum_{i=1}^n d_i^2\n",
        "\\end{align}\n",
        "\n",
        "This cost function denotes the total error present in the model which is the sum of the total errors of each individual data point.\n",
        "\n",
        "We can estimate the parameters of the model $B_0$ and $B_1$ by minimizing the error in the model by minimizing $D$. Thus we can find the regression line.\n",
        "\n",
        "This method of finding the parameters of the model and thus regression line is called **Ordinary Least Square Method**.\n"
      ],
      "metadata": {
        "id": "vpiSl8WZQUHx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRnp4vmdO5g9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}